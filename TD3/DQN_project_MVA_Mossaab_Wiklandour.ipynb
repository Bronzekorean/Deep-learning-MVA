{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import skvideo.io\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import sgd\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProject #3: Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
    "\n",
    "\\begin{equation*}\n",
    "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
    "\\end{equation*}\n",
    "\n",
    "where: \n",
    "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "We note the $Q$-function:\n",
    "\n",
    "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "Thus, the optimal Q function is:\n",
    "\\begin{equation*}\n",
    "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The environment, the agent and the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, act):\n",
    "        \"\"\"\n",
    "        One can act on the environment and obtain its reaction:\n",
    "        - the new state\n",
    "        - the reward of the new state\n",
    "        - should we continue the game?\n",
    "\n",
    "        :return: state, reward, game_over\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinitialize the environment to a random state and returns\n",
    "        the original state\n",
    "\n",
    "        :return: state\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Visualize in the console or graphically the current state\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
    "\n",
    "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
    "\n",
    "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
    "\n",
    "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, epsilon=0.1, n_action=4):\n",
    "        self.epsilon = epsilon\n",
    "        self.n_action = n_action\n",
    "    \n",
    "    def set_epsilon(self,e):\n",
    "        self.epsilon = e\n",
    "\n",
    "    def act(self,s,train=True):\n",
    "        \"\"\" This function should return the next action to do:\n",
    "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
    "        if train:\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
    "            else:\n",
    "                a = self.learned_act(s)\n",
    "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
    "            a = self.learned_act(s)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def learned_act(self,s):\n",
    "        \"\"\" Act via the policy of the agent, from a given state s\n",
    "        it proposes an action a\"\"\"\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s, n_s, a, r, game_over_):\n",
    "        \"\"\" This function is the core of the learning algorithm. \n",
    "        It takes as an input the current state s_, the next state n_s_\n",
    "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
    "        \n",
    "        Its goal is to learn a policy.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" This function returns basic stats if applicable: the\n",
    "        loss and/or the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\" This function allows to restore a model\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 1__:\n",
    "Explain the function act. Why is ```epsilon``` essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function act returns the act $\\pi(s)$ corresponding to the optimal action. If the agent is in training mode the function performs an exploration with rate epsilon this is what we call an epsilon-greedy strategy.\n",
    "\n",
    "$\\epsilon$ controls the exploration rate, when epsilon equals zero there is no exploration and the agent can get stuck in a non optimal action, if $\\epsilon$ is 1 the agent is acting randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
    "\n",
    "```python\n",
    "\n",
    "epoch = 300\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "\n",
    "# Number of won games\n",
    "score = 0\n",
    "loss = 0\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "    state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "    game_over = False\n",
    "\n",
    "    win = 0\n",
    "    lose = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        # The agent performs an action\n",
    "        action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "        prev_state = state\n",
    "        state, reward, game_over = env.act(action)\n",
    "\n",
    "        # Update the counters\n",
    "        if reward > 0:\n",
    "            win = win + reward\n",
    "        if reward < 0:\n",
    "            lose = lose -reward\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "    # Save as a mp4\n",
    "    if e % 10 == 0:\n",
    "        env.draw(e)\n",
    "\n",
    "    # Update stats\n",
    "    score += win-lose\n",
    "\n",
    "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "          .format(e, epoch, loss, win, lose, win-lose))\n",
    "    agent.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The game, *eat cheese*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
    "\n",
    "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0 #Correct typo here\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1 #Correct typo here\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:,-2:] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following elements are important because they correspond to the hyper parameters for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T=200\n",
    "temperature=0.3\n",
    "epochs_train=25 # set small when debugging\n",
    "epochs_test=10 # set small when debugging\n",
    "\n",
    "# display videos\n",
    "def display_videos(name):\n",
    "    video = io.open(name, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return '''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The position is where the rat can go. \n",
    "   - -1 can't go\n",
    "   - 0 can go\n",
    "   - 1 position of the rat\n",
    "   \n",
    "The board is reward as a funtion of $(x,y)$ coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super(RandomAgent, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def learned_act(self, s):\n",
    "       return np.random.randint(0, self.n_action, size=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 8.0/11.0. Average score (-3.0)\n",
      "Win/lose count 9.5/17.0. Average score (-5.25)\n",
      "Win/lose count 5.0/5.0. Average score (-3.5)\n",
      "Win/lose count 9.5/12.0. Average score (-3.25)\n",
      "Win/lose count 11.0/14.0. Average score (-3.2)\n",
      "Win/lose count 12.0/18.0. Average score (-3.6666666666666665)\n",
      "Win/lose count 7.0/24.0. Average score (-5.571428571428571)\n",
      "Win/lose count 5.5/16.0. Average score (-6.1875)\n",
      "Win/lose count 10.5/11.0. Average score (-5.555555555555555)\n",
      "Win/lose count 9.5/21.0. Average score (-6.15)\n",
      "Final score: -6.15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the game\n",
    "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
    "\n",
    "# Initialize the agent!\n",
    "agent = RandomAgent()\n",
    "\n",
    "test(agent,env,epochs_test,prefix='random')\n",
    "HTML(display_videos('random3.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume here that $T=\\infty$.\n",
    "\n",
    "***\n",
    "__Question 5__ Let $\\pi$ be a policy, show that:\n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{equation*}\n",
    "Finally, deduce that a plausible objective is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first identity is given by\n",
    "\\begin{align}\n",
    "Q^{\\pi}(s,a)&=E[ \\sum_{k=0}^{\\infty} \\gamma^k r_{t+k}|s_t = s, a_t = a] \\\\\n",
    "& = E[ r(s,a) + \\sum_{k=1}^{\\infty} \\gamma^k r_{t+k}|s_t = s, a_t = a] \\\\\n",
    "& =  r(s,a) + \\gamma E[E[\\sum_{k=0}^{\\infty}[\\gamma^k r_{t+1+k}|s_{t+1}=s',a_{t+1}=a']|s_t = s, a_t = a] \\\\\n",
    "&=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{align}\n",
    "\n",
    "The optimal policy veryfies\n",
    "\n",
    "\\begin{align}\n",
    "Q^{*}(s,a) &= \\max_{\\pi}E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')] \\\\\n",
    "&= \\max_{\\pi}r(s,a) + \\gamma \\sum(p(s_{t+1}=s' |s_t = s, a_t = a )Q^{\\pi}(s',a')\\\\\n",
    "&= r(s,a) + \\gamma \\max_{\\pi} \\sum(p(s_{t+1}=s' |s_t = s, a_t = a )Q^{\\pi'}(s',a') \n",
    "\\end{align}\n",
    "\n",
    "We can exchange the max and sum operators in this case because $ Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) $ .\n",
    "\n",
    "We have:\n",
    "\\begin{align}\n",
    "Q^{*}(s,a)&= r(s,a) + \\gamma \\sum(p(s_{t+1}=s' |s_t = s, a_t = a )\\max_{a'} Q^{*}(s',a') \\\\ \n",
    "&=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{align}\n",
    "\n",
    "We propose the following objective function that allows to satisty the previous equation if the network converges.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
    "\n",
    "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
    "\n",
    "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
    "\n",
    "3. Store $(s_t,a_t,s_{t+1})$;\n",
    "\n",
    "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
    "\n",
    "***\n",
    "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, max_memory=100):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "\n",
    "    def remember(self, m):\n",
    "        self.memory.append(m)\n",
    "        if len(self.memory) > self.max_memory:\n",
    "            self.memory.pop(0)\n",
    "\n",
    "    def random_access(self):\n",
    "        return self.memory[np.random.randint(0, len(self.memory), size=1)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The pipeline we will use for training is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(Agent):\n",
    "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
    "        super(DQN, self).__init__(epsilon = epsilon)\n",
    "\n",
    "        # Discount for Q learning\n",
    "        self.discount = 0.99\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        # number of state\n",
    "        self.n_state = n_state\n",
    "\n",
    "        # Memory\n",
    "        self.memory = Memory(memory_size)\n",
    "        \n",
    "        # Batch size when learning\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
    "        # Two steps: first memorize the states, second learn from the pool\n",
    "\n",
    "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
    "        \n",
    "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
    "        target_q = np.zeros((self.batch_size, 4))\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            ######## FILL IN\n",
    "            s_, n_s_, a_, r_, game_over_  = self.memory.random_access()\n",
    "            if game_over_:\n",
    "                input_states[i] = s_\n",
    "                target_q[i,a_] = r_\n",
    "            else:\n",
    "                input_states[i] = s_\n",
    "                target_q[i,a_] = r_  + self.discount*max(self.model.predict(n_s_.reshape([1,*s_.shape]))[0])\n",
    "            \n",
    "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
    "        target_q = np.clip(target_q, -3, 3)\n",
    "        l = self.model.train_on_batch(input_states, target_q)\n",
    "\n",
    "\n",
    "        return l\n",
    "\n",
    "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
    "        self.model.save_weights(name_weights, overwrite=True)\n",
    "        with open(name_model, \"w\") as outfile:\n",
    "            json.dump(self.model.to_json(), outfile)\n",
    "            \n",
    "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
    "        with open(name_model, \"r\") as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "        model.load_weights(name_weights)\n",
    "        model.compile(\"sgd\", \"mse\")\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "class DQN_FC(DQN):\n",
    "    def __init__(self, *args, lr=0.1,**kwargs):\n",
    "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
    "        \n",
    "        # NN Model\n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape=(5,5,self.n_state,)))\n",
    "        model.add(Dense(30,activation ='relu')) \n",
    "        model.add(Dense(4))\n",
    "        \n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/020 | Loss 0.0000 | Win/lose count 2.0/2.0 (0.0)\n",
      "Epoch 001/020 | Loss 0.0000 | Win/lose count 1.0/3.0 (-2.0)\n",
      "Epoch 002/020 | Loss 0.0000 | Win/lose count 2.5/4.0 (-1.5)\n",
      "Epoch 003/020 | Loss 0.0000 | Win/lose count 1.0/4.0 (-3.0)\n",
      "Epoch 004/020 | Loss 0.0000 | Win/lose count 0.5/3.0 (-2.5)\n",
      "Epoch 005/020 | Loss 0.0000 | Win/lose count 2.5/0 (2.5)\n",
      "Epoch 006/020 | Loss 0.0000 | Win/lose count 2.0/3.0 (-1.0)\n",
      "Epoch 007/020 | Loss 0.0000 | Win/lose count 2.0/3.0 (-1.0)\n",
      "Epoch 008/020 | Loss 0.0000 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 009/020 | Loss 0.0000 | Win/lose count 3.5/3.0 (0.5)\n",
      "Epoch 010/020 | Loss 0.0000 | Win/lose count 1.5/3.0 (-1.5)\n",
      "Epoch 011/020 | Loss 0.0000 | Win/lose count 1.5/3.0 (-1.5)\n",
      "Epoch 012/020 | Loss 0.0000 | Win/lose count 1.0/4.0 (-3.0)\n",
      "Epoch 013/020 | Loss 0.0000 | Win/lose count 1.5/4.0 (-2.5)\n",
      "Epoch 014/020 | Loss 0.0000 | Win/lose count 1.5/1.0 (0.5)\n",
      "Epoch 015/020 | Loss 0.0000 | Win/lose count 2.0/1.0 (1.0)\n",
      "Epoch 016/020 | Loss 0.0000 | Win/lose count 3.5/0 (3.5)\n",
      "Epoch 017/020 | Loss 0.0000 | Win/lose count 1.5/4.0 (-2.5)\n",
      "Epoch 018/020 | Loss 0.0000 | Win/lose count 2.0/5.0 (-3.0)\n",
      "Epoch 019/020 | Loss 0.0000 | Win/lose count 0.5/3.0 (-2.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_train = 20\n",
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "train(agent_fc, env, epochs_train, prefix='fc_train')\n",
    "HTML(display_videos('fc_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_CNN(DQN):\n",
    "    def __init__(self, *args,lr=0.1,**kwargs):\n",
    "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(50,(2,2),input_shape=(5,5,self.n_state,),activation='relu'))\n",
    "        model.add(Conv2D(30,(2,2),activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4))\n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        \n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/020 | Loss 0.0099 | Win/lose count 0.5/7.0 (-6.5)\n",
      "Epoch 001/020 | Loss 0.0112 | Win/lose count 3.0/0 (3.0)\n",
      "Epoch 002/020 | Loss 0.0091 | Win/lose count 2.5/1.0 (1.5)\n",
      "Epoch 003/020 | Loss 0.0243 | Win/lose count 0.5/2.0 (-1.5)\n",
      "Epoch 004/020 | Loss 0.0147 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 005/020 | Loss 0.0052 | Win/lose count 2.0/6.0 (-4.0)\n",
      "Epoch 006/020 | Loss 0.0075 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 007/020 | Loss 0.0136 | Win/lose count 2.0/4.0 (-2.0)\n",
      "Epoch 008/020 | Loss 0.0044 | Win/lose count 0.5/5.0 (-4.5)\n",
      "Epoch 009/020 | Loss 0.0060 | Win/lose count 2.5/4.0 (-1.5)\n",
      "Epoch 010/020 | Loss 0.0049 | Win/lose count 0.5/1.0 (-0.5)\n",
      "Epoch 011/020 | Loss 0.0239 | Win/lose count 1.0/3.0 (-2.0)\n",
      "Epoch 012/020 | Loss 0.0052 | Win/lose count 2.5/1.0 (1.5)\n",
      "Epoch 013/020 | Loss 0.0073 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 014/020 | Loss 0.0039 | Win/lose count 2.0/2.0 (0.0)\n",
      "Epoch 015/020 | Loss 0.0036 | Win/lose count 1.0/0 (1.0)\n",
      "Epoch 016/020 | Loss 0.0066 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 017/020 | Loss 0.0026 | Win/lose count 1.0/3.0 (-2.0)\n",
      "Epoch 018/020 | Loss 0.0005 | Win/lose count 1.0/5.0 (-4.0)\n",
      "Epoch 019/020 | Loss 0.0111 | Win/lose count 2.0/5.0 (-3.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_train = 20\n",
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "train(agent_cnn,env,epochs_train,prefix='cnn_train')\n",
    "HTML(display_videos('cnn_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of the CNN\n",
      "Epoch 000/020 | Loss 0.0000 | Win/lose count 1.5/1.0 (0.5)\n",
      "Epoch 001/020 | Loss 0.0000 | Win/lose count 1.5/4.0 (-2.5)\n",
      "Epoch 002/020 | Loss 0.0000 | Win/lose count 2.0/5.0 (-3.0)\n",
      "Epoch 003/020 | Loss 0.0000 | Win/lose count 0.5/1.0 (-0.5)\n",
      "Epoch 004/020 | Loss 0.0000 | Win/lose count 2.5/2.0 (0.5)\n",
      "Epoch 005/020 | Loss 0.0000 | Win/lose count 2.0/2.0 (0.0)\n",
      "Epoch 006/020 | Loss 0.0000 | Win/lose count 0.5/2.0 (-1.5)\n",
      "Epoch 007/020 | Loss 0.0000 | Win/lose count 2.0/1.0 (1.0)\n",
      "Epoch 008/020 | Loss 0.0000 | Win/lose count 1.0/1.0 (0.0)\n",
      "Epoch 009/020 | Loss 0.0000 | Win/lose count 1.5/1.0 (0.5)\n",
      "Epoch 010/020 | Loss 0.0000 | Win/lose count 1.0/1.0 (0.0)\n",
      "Epoch 011/020 | Loss 0.0000 | Win/lose count 1.5/5.0 (-3.5)\n",
      "Epoch 012/020 | Loss 0.0000 | Win/lose count 1.0/1.0 (0.0)\n",
      "Epoch 013/020 | Loss 0.0000 | Win/lose count 0.5/3.0 (-2.5)\n",
      "Epoch 014/020 | Loss 0.0000 | Win/lose count 1.5/2.0 (-0.5)\n",
      "Epoch 015/020 | Loss 0.0000 | Win/lose count 1.5/4.0 (-2.5)\n",
      "Epoch 016/020 | Loss 0.0000 | Win/lose count 2.5/3.0 (-0.5)\n",
      "Epoch 017/020 | Loss 0.0000 | Win/lose count 2.0/2.0 (0.0)\n",
      "Epoch 018/020 | Loss 0.0000 | Win/lose count 1.0/3.0 (-2.0)\n",
      "Epoch 019/020 | Loss 0.0000 | Win/lose count 1.0/0 (1.0)\n",
      "Test of the FC\n",
      "Epoch 000/020 | Loss 0.0000 | Win/lose count 1.0/4.0 (-3.0)\n",
      "Epoch 001/020 | Loss 0.0000 | Win/lose count 3.0/6.0 (-3.0)\n",
      "Epoch 002/020 | Loss 0.0000 | Win/lose count 2.5/4.0 (-1.5)\n",
      "Epoch 003/020 | Loss 0.0000 | Win/lose count 1.0/3.0 (-2.0)\n",
      "Epoch 004/020 | Loss 0.0000 | Win/lose count 1.5/2.0 (-0.5)\n",
      "Epoch 005/020 | Loss 0.0000 | Win/lose count 2.0/0 (2.0)\n",
      "Epoch 006/020 | Loss 0.0000 | Win/lose count 2.0/1.0 (1.0)\n",
      "Epoch 007/020 | Loss 0.0000 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 008/020 | Loss 0.0000 | Win/lose count 2.0/2.0 (0.0)\n",
      "Epoch 009/020 | Loss 0.0000 | Win/lose count 0.5/3.0 (-2.5)\n",
      "Epoch 010/020 | Loss 0.0000 | Win/lose count 1.0/0 (1.0)\n",
      "Epoch 011/020 | Loss 0.0000 | Win/lose count 1.5/1.0 (0.5)\n",
      "Epoch 012/020 | Loss 0.0000 | Win/lose count 2.5/1.0 (1.5)\n",
      "Epoch 013/020 | Loss 0.0000 | Win/lose count 2.5/0 (2.5)\n",
      "Epoch 014/020 | Loss 0.0000 | Win/lose count 4.0/2.0 (2.0)\n",
      "Epoch 015/020 | Loss 0.0000 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 016/020 | Loss 0.0000 | Win/lose count 1.5/6.0 (-4.5)\n",
      "Epoch 017/020 | Loss 0.0000 | Win/lose count 0.5/4.0 (-3.5)\n",
      "Epoch 018/020 | Loss 0.0000 | Win/lose count 1.0/4.0 (-3.0)\n",
      "Epoch 019/020 | Loss 0.0000 | Win/lose count 1.5/1.0 (0.5)\n"
     ]
    }
   ],
   "source": [
    "print('Test of the CNN')\n",
    "test(agent_cnn,env,20,prefix='cnn_test')\n",
    "print('Test of the FC')\n",
    "test(agent_fc,env,20,prefix='fc_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_test10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('fc_test10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN are far better than normal feed forward neural network. The gap in score widen with temperature\n",
    "\n",
    "The algorithm tends to not explore the map which can be an issue. and get stuck in a certain patern. This does not help to improve the score. This is more frequent when tempreture is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
    "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
    "2. Append via the environment a new state that describes if a cell has been visited or not\n",
    "\n",
    "***\n",
    "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_explore(agent,env,epoch,decay_parameter_epsilon=0.3,prefix=''):\n",
    "    #New training procedure that tries to improve the exploration of the algorithm\n",
    "    #decay_parameter_epsilon in order to use the decreasing $\\epsilon$-greedy exploration\n",
    "    \n",
    "    \n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for ep in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        agent.set_epsilon(agent.epsilon*(1-decay_parameter_epsilon))\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action, train=True)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if ep % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(ep, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
    "        \n",
    "class EnvironmentExploring(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "        self.malus_position = np.zeros((grid_size,grid_size)) #define maluses when going to a previously visited position\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action,train=False):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "        #During the training phase going back to a position where the rat have already been before tends to decrease the \n",
    "        #total reward hence there is this train parameter that we have added (it tries to enforce the exploration)\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1     \n",
    "        \n",
    "        ## In Environment exploring:\n",
    "        # You will have to change n_state to 3 because you will use one more layer!\n",
    "        reward = 0\n",
    "        if train:\n",
    "            reward = -self.malus_position[self.x, self.y]\n",
    "        self.malus_position[self.x, self.y] = 0.1\n",
    "\n",
    "        reward = reward + self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        # 3 \"feature\" states instead of 2\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:,-2:] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
    "        #At the begining the malus_position array must be setted to zero\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/020 | Loss 0.1820 | Win/lose count 1.5/21.20000000000004 (-19.70000000000004)\n",
      "Epoch 001/020 | Loss 0.2357 | Win/lose count 0.5/22.20000000000005 (-21.70000000000005)\n",
      "Epoch 002/020 | Loss 0.0059 | Win/lose count 1.5/19.200000000000003 (-17.700000000000003)\n",
      "Epoch 003/020 | Loss 0.0054 | Win/lose count 0.5/19.70000000000001 (-19.20000000000001)\n",
      "Epoch 004/020 | Loss 0.0760 | Win/lose count 0.5/21.600000000000023 (-21.100000000000023)\n",
      "Epoch 005/020 | Loss 0.1166 | Win/lose count 0/20.80000000000003 (-20.80000000000003)\n",
      "Epoch 006/020 | Loss 0.1665 | Win/lose count 0.5/19.80000000000001 (-19.30000000000001)\n",
      "Epoch 007/020 | Loss 0.0458 | Win/lose count 0/19.900000000000013 (-19.900000000000013)\n",
      "Epoch 008/020 | Loss 0.0039 | Win/lose count 0/19.900000000000013 (-19.900000000000013)\n",
      "Epoch 009/020 | Loss 0.1644 | Win/lose count 0/20.000000000000014 (-20.000000000000014)\n",
      "Epoch 010/020 | Loss 0.1609 | Win/lose count 0.5/19.80000000000001 (-19.30000000000001)\n",
      "Epoch 011/020 | Loss 0.0051 | Win/lose count 0/20.000000000000014 (-20.000000000000014)\n",
      "Epoch 012/020 | Loss 0.1435 | Win/lose count 0/20.80000000000003 (-20.80000000000003)\n",
      "Epoch 013/020 | Loss 0.2098 | Win/lose count 0/20.000000000000014 (-20.000000000000014)\n",
      "Epoch 014/020 | Loss 0.1640 | Win/lose count 0/20.000000000000014 (-20.000000000000014)\n",
      "Epoch 015/020 | Loss 0.0019 | Win/lose count 0/20.000000000000014 (-20.000000000000014)\n",
      "Epoch 016/020 | Loss 0.0010 | Win/lose count 0/20.000000000000014 (-20.000000000000014)\n",
      "Epoch 017/020 | Loss 0.0040 | Win/lose count 0/20.000000000000014 (-20.000000000000014)\n",
      "Epoch 018/020 | Loss 0.0015 | Win/lose count 0/20.000000000000014 (-20.000000000000014)\n",
      "Epoch 019/020 | Loss 0.0037 | Win/lose count 0/20.000000000000014 (-20.000000000000014)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32,n_state=3)\n",
    "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n",
    "HTML(display_videos('cnn_train_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/010 | Loss 0.0000 | Win/lose count 0/0 (0)\n",
      "Epoch 001/010 | Loss 0.0000 | Win/lose count 0/0 (0)\n",
      "Epoch 002/010 | Loss 0.0000 | Win/lose count 0/0 (0)\n",
      "Epoch 003/010 | Loss 0.0000 | Win/lose count 0/0 (0)\n",
      "Epoch 004/010 | Loss 0.0000 | Win/lose count 0/0 (0)\n",
      "Epoch 005/010 | Loss 0.0000 | Win/lose count 0/0 (0)\n",
      "Epoch 006/010 | Loss 0.0000 | Win/lose count 0/0 (0)\n",
      "Epoch 007/010 | Loss 0.0000 | Win/lose count 0/0 (0)\n",
      "Epoch 008/010 | Loss 0.0000 | Win/lose count 0/0 (0)\n",
      "Epoch 009/010 | Loss 0.0000 | Win/lose count 0/0 (0)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cnn_test_explore10.mp4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-598634141cce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cnn_test_explore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisplay_videos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cnn_test_explore10.mp4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-62a62a040502>\u001b[0m in \u001b[0;36mdisplay_videos\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# display videos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdisplay_videos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mvideo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r+b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase64\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb64encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     return '''<video alt=\"test\" controls>\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cnn_test_explore10.mp4'"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
    "HTML(display_videos('cnn_test_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
